Tổng quan & Đặt vấn đề (Introduction)
Nhiệm vụ: Viết phần mở đầu, giải thích tại sao chọn đề tài này và bối cảnh Fintech.
Bối cảnh: Ngân hàng cần phát hiện gian lận nhưng dữ liệu nội bộ không thể chia sẻ ra ngoài do bảo mật.


Trong kỷ nguyên số hóa, công nghệ tài chính đang phát triển bùng nổ, mang lại sự tiện lợi vượt bậc cho người dùng. Tuy nhiên, đi kèm với đó là sự gia tăng phức tạp và tinh vi của các hành vi gian lận giao dịch tài chính. Việc phát hiện và ngăn chặn gian lận trở thành nhiệm vụ sống còn đối với các ngân hàng để bảo vệ tài sản và uy tín.

Vấn đề: Mặc dù dữ liệu bị cô lập, các ngân hàng vẫn có nhu cầu cấp thiết là muốn học chung các "pattern" (mẫu) gian lận của nhau để đối phó với các thủ đoạn tội phạm ngày càng tinh vi.
Vấn đề đặt ra là: Làm thế nào để tận dụng tri thức từ dữ liệu của nhiều ngân hàng khác nhau mà không vi phạm quy tắc bảo mật? Các phương pháp học máy truyền thống yêu cầu gom dữ liệu về một máy chủ trung tâm là không khả thi trong bối cảnh này do rào cản pháp lý và quyền riêng tư. Hơn nữa, dữ liệu thô tại mỗi ngân hàng có thể khác nhau, gây khó khăn cho việc đồng bộ hóa.
Giải pháp đề xuất: Sử dụng Federated Learning (FL) để huấn luyện chung mà không cần gom dữ liệu về một chỗ.
 Dù dữ liệu thô khác nhau, các bên sẽ thống nhất một quy trình Feature Engineering để đảm bảo vector đặc trưng (như amount, transaction_hour...) là giống nhau.
Mục tiêu đề tài: Mục tiêu của đề tài là xây dựng một hệ thống phát hiện gian lận mô phỏng thực tế, đảm bảo quyền riêng tư và bảo mật dữ liệu.
Tuyên bố chốt (Thesis Statement): Đề tài sử dụng Federated Learning với mô hình Neural Network để phát hiện gian lận giao dịch tài chính, trong đó mỗi ngân hàng huấn luyện mô hình cục bộ trên dữ liệu đã gán nhãn nội bộ và chỉ chia sẻ tham số mô hình, đảm bảo quyền riêng tư và bảo mật dữ liệu?
Cơ sở lý thuyết & Lựa chọn mô hình (Theory & Model Selection)
Nhiệm vụ: Giải thích lý do kỹ thuật đằng sau việc chọn mô hình 
Mô hình được chọn: Neural Network (hoặc Logistic Regression).
Lý giải tại sao chọn:
Dựa trên Gradient-based để dùng thuật toán FedAvg chuẩn.
Dễ triển khai và giải thích, phù hợp với bài toán fraud detection.


1. Cơ sở lý thuyết 
Nền tảng của Federated Learning dựa trên bài toán tối ưu hóa phân tán. Thay vì tối ưu hóa một hàm mất mát (Loss) trên một tập dữ liệu tập trung, chúng ta tối ưu hóa hàm mục tiêu tổng thể dựa trên dữ liệu phân tán tại K thiết bị.
a, Bài toán tối ưu hóa tổng thể
Mục tiêu là tìm bộ trọng số w sao cho hàm mất mát toàn cục f(w) là nhỏ nhất:
f(w) = k=1KnknFk(w)
Trong đó:
nk: Số lượng mẫu dữ liệu tại thiết bị k
n: Tổng số lượng mẫu trên toàn hệ thống
Fk(w): Hàm mất mát cục bộ của thiết bị k
b, Cơ chế Gradient-based trong FedAvg
Thuật toán FedAvg cải tiến dựa trên Stochastic Gradient Descent (SGD). Điểm khác biệt là thay vì cập nhật trọng số sau mỗi bước gradient đơn lẻ tại server, mỗi thiết bị sẽ thực hiện nhiều bước cập nhật cục bộ:
Cập nhật cục bộ: Thiết bị k thực hiện E chu kỳ (epochs) huấn luyện bằng cách sử dụng đạo hàm: wkw- Fk(w)
Hội tụ trung bình: Sau khi các thiết bị hoàn tất, Server thu thập các trọng số wk và tính trung bình cộng để cập nhật mô hình gốc.
c, Logic Regression (LR) trong bối cảnh FL
Trong FL, Logistic Regression thường được dùng cho bài toán phân loại nhị phân (ví dụ: Gian lận hay Không gian lận).
Mô hình dự đoán: Xác suất đầu ra được tính bằng hàm Sigmoid:
hw(x) = 11 + e-(wTx+b)
Trong đó vector w là vector trọng số và b là độ chệch
Hàm mất mát cục bộ (Local Loss): Mỗi thiết bị k sẽ tối ưu hàm Cross-Entropy:
Fk(w) = -1nki=1nk[yilog(hw(xi)) + (1 - yi)log(1 - hw(xi))]
Cập nhật Gradient: Tại mỗi thiết bị, trọng số được cập nhật theo hướng giảm sai số:
wkw- Fk(w)

c, Neural Network (NN) trong bối cảnh FL
Neural Network mở rộng khả năng của LR bằng cách xếp chồng nhiều lớp và dùng hàm kích hoạt phi tuyến để học các đặc trưng phức tạp.
Mô hình dự đoán (Nhiều lớp): Đầu ra của tầng l là đầu vào của tầng l+1:
a(l)=(W(l)a(l-1)+b(l))
Trong đó  thường là hàm ReLU (max(0, z)) ở các tầng ẩn để tránh triệt tiêu gradient.
Hàm mất mát tổng quát: Với bài toán phân loại nhiều lớp, NN thường dùng hàm Softmax ở tầng cuối và mất mát Categorical Cross-Entropy:
L(y, y)=-jyilog(yj)
Lan truyền ngược (Backpropagation) trong FL: Gradient không chỉ tính một lần mà được tính cho từng lớp thông qua quy tắc chuỗi (Chain Rule). Tại mỗi thiết bị, thuật toán sẽ thực hiện nhiều bước lặp (Local Epochs) để tối ưu hóa bộ tham số = {W, b}  trước khi gửi kết quả tổng hợp về Server:
k(t+1) = k(t)-Fkk
d. Thuật toán dựa trên cây (Tree-based Models) và thách thức trong FL
Các mô hình như Random Forest hay Gradient Boosting Machine (GBM) thường được ưu tiên trong phát hiện gian lận vì khả năng xử lý dữ liệu bảng (tabular data) rất tốt. Tuy nhiên, trong bối cảnh Federated Learning, chúng bộc lộ một số hạn chế:
Khó khăn trong việc tổng hợp (Aggregation): Không giống như NN hay LR có các trọng số dạng số thực dễ dàng tính trung bình cộng ($\text{FedAvg}$), các thuật toán cây dựa trên việc chia nhánh (splits) tại các nút. Việc "trung bình cộng" hai cái cây có cấu trúc khác nhau từ hai thiết bị khác nhau là một bài toán cực kỳ phức tạp về mặt toán học.
Rò rỉ quyền riêng tư: Để huấn luyện cây trong FL, đôi khi máy chủ cần biết các giá trị ngưỡng (thresholds) của các thuộc tính dữ liệu. Điều này vô tình làm lộ phân phối dữ liệu của người dùng, vi phạm nguyên tắc cốt lõi của FL.
Chi phí truyền thông: Việc gửi cấu trúc toàn bộ cây hoặc các biểu đồ tần suất (histograms) thường tốn kém băng thông hơn so với việc chỉ gửi các vector trọng số của NN.

2. Lý do chọn mô hình
Sau khi xem xét các thuật toán Machine Learning phổ biến (như Logistic Regression, Decision Trees, SVM), chúng tôi quyết định lựa chọn Mạng nơ-ron nhân tạo (Neural Network) làm mô hình cốt lõi cho hệ thống Federated Learning với các lý do sau:
2.1. Khả năng học đặc trưng phi tuyến tính (Non-linearity)
Phát hiện gian lận là một bài toán có độ phức tạp cao, nơi các hành vi vi phạm thường được che giấu dưới nhiều lớp giao dịch khác nhau.
Hạn chế của LR & các thuật toán tuyến tính: Chỉ có thể phân loại dữ liệu dựa trên các đường biên thẳng. Nếu dữ liệu bị chồng lấn hoặc có quan hệ phi tuyến, các mô hình này sẽ có tỉ lệ False Negative (bỏ sót gian lận) rất cao.
Ưu điểm của NN: Thông qua các lớp ẩn (Hidden Layers) và hàm kích hoạt (Activation Functions) như ReLU hay Sigmoid, NN có khả năng tạo ra các đường biên phân loại cong và phức tạp, bao phủ được các tổ hợp dữ liệu bất thường nhất.
2.2. Khả năng tự trích xuất đặc trưng (Feature Engineering)
Trong môi trường Federated Learning, dữ liệu thô nằm phân tán trên thiết bị người dùng và kỹ sư không thể tiếp cận trực tiếp để phân tích.
Với các thuật toán khác: Cần sự can thiệp thủ công của con người để chọn lọc và biến đổi đặc trưng (feature selection).
Với NN: Mô hình có khả năng tự động học các đặc trưng quan trọng từ dữ liệu thô thông qua quá trình lan truyền ngược (Backpropagation). Điều này giúp hệ thống hoạt động hiệu quả ngay cả khi dữ liệu đầu vào có tính đa dạng và không đồng nhất (Non-IID).
2.3. Sự tương thích tối ưu với thuật toán FedAvg
Neural Network được cấu tạo từ các ma trận trọng số (weights), điều này tạo điều kiện thuận lợi cho việc triển khai Federated Averaging:
Nén và truyền tải: Các tham số của NN có thể được nén (Compression) hoặc lượng tử hóa (Quantization) để giảm dung lượng khi gửi qua mạng mà không làm mất quá nhiều độ chính xác.
Cập nhật gradient: NN cho phép tính toán gradient cực kỳ chi tiết cho từng lớp, giúp việc tổng hợp mô hình tại Server đạt được sự hội tụ nhanh hơn so với việc gộp các cây quyết định (Decision Trees) hay các mô hình dựa trên thực thể khác.
2.4. Khả năng mở rộng và cá nhân hóa (Personalization)
NN cho phép thực hiện Fine-tuning (tinh chỉnh) dễ dàng. Sau khi nhận được mô hình chung từ Server, mỗi thiết bị có thể tiếp tục huấn luyện thêm một vài vòng trên dữ liệu cá nhân để mô hình trở nên "nhạy" hơn với hành vi riêng biệt của người dùng đó mà vẫn giữ được tri thức chung của cộng đồng.
2.5. Khắc phục hạn chế của các mô hình Tree-based
Mặc dù các thuật toán như Random Forest rất mạnh mẽ trong việc xử lý dữ liệu bảng, chúng tôi không lựa chọn chúng vì:
Tính khả thi của thuật toán: Các phiên bản Federated cho mô hình cây (như Federated Forest) yêu cầu các giao thức truyền thông rất phức tạp và khó cài đặt chuẩn hóa như FedAvg của Neural Network.
Sự linh hoạt: Neural Network dễ dàng tích hợp các kỹ thuật bảo mật bổ sung như Differential Privacy (thêm nhiễu vào gradient) hơn là các mô hình cây.






Dữ liệu & Kỹ thuật xử lý đặc trưng (Data & Feature Engineering)
Xử lý vấn đề "Dữ liệu khác nhau thì train chung kiểu gì?".
Nguồn dữ liệu: Dữ liệu giao dịch nội bộ tại mỗi client (ngân hàng).
Nguồn gốc nhãn (Label): Giải thích nhãn không phải do FL tạo ra mà từ thực tế (khiếu nại, chargeback, nhân viên xác minh).
Quy tắc "Bất di bất dịch" (Quan trọng):
Raw data có thể khác nhau, nhưng Vector đặc trưng (Feature Vector) sau khi xử lý PHẢI GIỐNG NHAU.
Đề xuất Schema chung: Trình bày bảng feature đã thống nhất (amount, transaction_hour, device_type,...) .
Xử lý thiếu dữ liệu: Quy định điền 0 hoặc unknown nếu thiếu feature

Quy trình hoạt động chi tiết (System Workflow & Algorithm)
Nhiệm vụ: Mô tả kỹ thuật cốt lõi (Core) của hệ thống FL.
Bước 1 - Khởi tạo: Server tạo mô hình NN 
Bước 2 - Phân phối: Gửi model giống hệt nhau cho các cl
Bước 3 - Huấn luyện cục bộ (Client):
Bước 4 - Gửi cập nhật:
 Bước 5 - Tổng hợp (Server): +1
Bước 6 & 7:.Lặp lại cho đến khi hội tụ và triển khai model cuối cùng xuống các ngân hàng để chạy real-time 


Thảo luận, Đánh giá & Kết luận (Discussion & Conclusion)
Nhiệm vụ: Trả lời các câu hỏi phản biện và tổng kết.
Giải đáp thắc mắc thường gặp (Q&A):
Client & Server có train khác nhau không? -> Không, cùng model, loss, optimizer .
Dataset khác nhau train chung được không? -> Chỉ được khi feature vector giống nhau (nhắc lại ý của Người 3 để nhấn mạnh).
+1
Đánh giá an toàn: FL an toàn hơn Centralized nhưng không tuyệt đối 100%, có thể kết hợp Secure Aggregation .
Kết luận:
Ý tưởng đúng thực tế, workflow rõ ràng.
Mô hình Neural Network là lựa chọn tối ưu cho đề tài này.


